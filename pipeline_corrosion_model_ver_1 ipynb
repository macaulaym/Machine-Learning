{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"pipeline_corrosion_model_ver_1 ipynb","provenance":[],"collapsed_sections":["QW3fvjPwZQ6V"],"toc_visible":true,"machine_shape":"hm","mount_file_id":"1i_oSzSOQpOMY3KwUZvD-l2MVSpbjtljU","authorship_tag":"ABX9TyNMd2nVln0Arar/zff+s6oh"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"PzsgO6iLIf5q"},"source":["# Data Exploration"]},{"cell_type":"markdown","metadata":{"id":"lc9DwQzKllwO"},"source":["## Mounting Pipeline Project Directory in Google Cloud Drive to Google Colab"]},{"cell_type":"code","metadata":{"id":"vEMln6d3uAb_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636696125622,"user_tz":0,"elapsed":33645,"user":{"displayName":"M M","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghi3qvzTPdx1nNvyRCeUWixEQOzkL_nGAXS2jNThg=s64","userId":"03096318492003078770"}},"outputId":"87e3a789-4001-46bb-8177-b933c9e6d04a"},"source":["from google.colab import drive #importing the Google Colab module and drive function\n","import os # importing os module\n","drive.mount('/content/drive') # mounting Google Drive to Google Colab\n","os.chdir('/content/drive/MyDrive/University_of_Kent/PhD/Research/Experiments/Pipeline_project') #Changing to dir. with pipeline project files.\n","print(os.getcwd()) # getting the current directory path details."],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/University_of_Kent/PhD/Research/Experiments/Pipeline_project\n"]}]},{"cell_type":"markdown","metadata":{"id":"gdNx3GOllpOv"},"source":["## Importing modules and libraries"]},{"cell_type":"code","metadata":{"id":"wiG67oUsV4CH","executionInfo":{"status":"ok","timestamp":1636696128002,"user_tz":0,"elapsed":2384,"user":{"displayName":"M M","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghi3qvzTPdx1nNvyRCeUWixEQOzkL_nGAXS2jNThg=s64","userId":"03096318492003078770"}}},"source":["import glob # importing the glob module which is a path traversing dir. library\n","import numpy as np\n","import tensorflow as tf\n","\n","from os import path, listdir\n","from PIL import Image # Python image library\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras import datasets, layers, models\n","from tqdm import tqdm # provides progress details for for-loops\n","\n","from skimage.io import imread # we call the imread function from the skimage module. imread function reads images.\n","from skimage.transform import resize # we call the resize function from the skimage module. resize resizes images.\n","from skimage.color import rgb2gray  # we call the rgb2gray function from the skimage.color module. rgb2gray function converts an RGB (colours) to greyscale (black and white)."],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Vwycx0nuY7oY"},"source":["## Accessing the Data"]},{"cell_type":"code","metadata":{"id":"XmdLGQuqJZkR","executionInfo":{"status":"ok","timestamp":1636696128003,"user_tz":0,"elapsed":11,"user":{"displayName":"M M","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghi3qvzTPdx1nNvyRCeUWixEQOzkL_nGAXS2jNThg=s64","userId":"03096318492003078770"}}},"source":["# Accessing the data in (colour or) greyscale\n","\n","def images_ds2features(pathin, label, samples=0, greyscale=False): \n","  \"\"\"\n","  The function reads labelled images from directories. \n","\n","  Arguments (or Parameters):\n","      pathin: string\n","              The path of the images.\n","      label: int\n","             This is the label you want to assign to the images in the dir.\n","      samples: int\n","               The number of random samples we want to draw/ access/ retrieve from the dir.\n","               If 0, then no random sampling is chosen, instead the entire dataset is retrieved.\n","      greyscale: bool\n","                 boolean for retrieving greyscale images. \n","\n","  Returns:\n","      images: list\n","              list of images from specified directory\n","      labels: list \n","              list of labels.\n","      \n","  Raises:\n","      Not Applicable at the moment.\n","  \"\"\"\n","\n","  images = [] # create a list called images.\n","  targets = [] # create a list called targets.\n","  count=0 # variable counter to be used for random sampling (if applicable).\n","  out_shape = (176, 320) if greyscale else (176, 320, 3) # We are defining the width (columns) = 320 and height (rows) = 176, output shape (that we want for) the images.\n","  img_files_list = listdir(pathin) # We get a list of files from the pathin dir. \n","\n","  for img_file_path in tqdm(img_files_list, total=len(img_files_list)): # Iterates through every filename in img_files_list and assigns each file to img_file_path (from img_files_list) with every run of the loop.\n","    if not img_file_path.endswith(\".jpg\") and not img_file_path.endswith(\".png\"): # checks if it is an image file.\n","      continue # if not an image file, program ignores file and moves to check next file.\n","\n","    full_path = path.join(pathin, img_file_path)\n","\n","    if (0 <= count < samples) or samples==0: # sampling occurs \n","      _image = imread(full_path, as_gray=greyscale) # we read the image from file img_file_path. \n","      \n","      _image = resize(_image, output_shape=out_shape, mode='constant', anti_aliasing=True) # we resize the image to the dimensions set earlier\n","      _image = _image.astype('float32') # we make sure it is 32 bit floats instead of 64 which is default. Faster training no loss of accuracy\n","\n","      images.append(_image) # we are appending the refactored (e.g. resized, retyped etc.) image array to the images list.\n","      targets.append(label) # we are appending the label. Note: we are going to end with the same amount of labels as the nos.of images in the sample.\n","      count+=1 \n","\n","  return images,targets "],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"myqhnHsxL6tk","executionInfo":{"status":"ok","timestamp":1636696128006,"user_tz":0,"elapsed":12,"user":{"displayName":"M M","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghi3qvzTPdx1nNvyRCeUWixEQOzkL_nGAXS2jNThg=s64","userId":"03096318492003078770"}}},"source":["# Access the image data in colour (RGB): deprecated (obselete function - has been replaced with images_ds2features(pathin, label, samples=0, greyscale=False)function)\n","# Function is not called in program.\n","\n","def read_imgs_from(pathin, samples=0): # A function definition named read_imgs_from, which has pathin parameter passed to it.\n","  images = [] # create a list called images.\n","  count=0\n","  for f in glob.iglob(path.join(pathin, '*')): # For every ('*') image in file in pathin, \n","    if (samples>0 and samples >count) or samples==0:\n","      images.append(np.asarray(Image.open(f))) # open the image file and append to a numpy array and then append to the list called images. \n","      count+=1\n","  images=np.array(images) # Convert the list named images (the outer list) into a numpy array as well.\n","\n","  print(pathin)\n","  print(images.shape) \n","  return images "],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"d2Mo7spOlqhb"},"source":["# get the path for high, medium etc.\n","path_train = path.join('pipeline_corrosion_dataset', 'Train_Data') # Name the path 'path_train'.\n","paths_high = path.join(path_train, 'high') # Take the path 'path_train' and add the string 'high' to it - in other words, construct a new path that leads to the path: 'pipeline_corrosion_dataset', 'Train_Data', 'high'.\n","paths_med = path.join(path_train, 'medium') # Take the path 'path_train' and add the string 'med' to it - in other words, construct a new path that leads to the path: 'pipeline_corrosion_dataset', 'Train_Data', 'med'.\n","paths_low = path.join(path_train, 'low')# Take the path 'path_train' and add the string 'low' to it - in other words, construct a new path that leads to the path: 'pipeline_corrosion_dataset', 'Train_Data', 'low'.\n","paths_no = path.join(path_train, 'no') # Take the path 'path_train' and add the string 'no' to it - in other words, construct a new path that leads to the path: 'pipeline_corrosion_dataset', 'Train_Data', 'no'.\n","\n","# from the paths read each dataset to its own list of images\n","samples=0\n","X_high, y_high = images_ds2features(paths_high, 3, samples=samples, greyscale=False) #samples (5x image files) is read from the constructed paths_high, and passes them into the function read_imgs_from, and then passes the output from the function into the container(variable) called images_high.\n","X_med, y_med = images_ds2features(paths_med, 2,  samples=samples, greyscale=False) #samples (5x image files) is read from the constructed paths_med, and passes them into the function read_imgs_from, and then passes the output from the function into the container(variable) called images_med.\n","X_low, y_low = images_ds2features(paths_low, 1, samples=samples, greyscale=False) #samples (5x image files) is read from the constructed paths_low, and passes them into the function read_imgs_from, and then passes the output from the function into the container(variable) called images_low.\n","X_no, y_no = images_ds2features(paths_no, 0, samples=samples, greyscale=False) #samples (5x image files) is read from the constructed paths_no, and passes them into the function read_imgs_from, and then passes the output from the function into the container(variable) called images_no"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PtcJlT6aZGUA"},"source":["# Feature Preparation/ or Engineering"]},{"cell_type":"code","metadata":{"id":"oXqAeIhuirRi"},"source":["# Feature prep/ engineering\n","\n","#Aligning the data (the features X must match the labels in vector y: there must be a one to one (1-1) mapping)\n","y = y_high + y_med + y_low + y_no # We place the medium image files before the no image files in the list into vector y.\n","y = np.array(y) # Convert the list y into a numpy array.\n","print(y.shape) \n","\n","X = X_high + X_med + X_low + X_no # We create a vertical stack, placing the medium images on top and the no images at the bottom, similar to line 9 above.\n","X = np.array(X)\n","#X.reshape(-1,1)\n","print(X.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QW3fvjPwZQ6V"},"source":["# Data Augmentation"]},{"cell_type":"code","metadata":{"id":"7XkqqYNIiz3w"},"source":["# Data Augmentation (if necessary)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7FuDCQ9uZYyq"},"source":["# Data Splitting"]},{"cell_type":"code","metadata":{"id":"KQFXqrGSi9JM"},"source":["# Split data into train and test ( and validation if necessary)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25,stratify=y, random_state=42, shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R494MC2hZh9X"},"source":["# Defining Model Architecture"]},{"cell_type":"code","metadata":{"id":"WI9FrOCPjCpN"},"source":["# Define model architecture\n","# This section creates the first part of the convolutional neural network architecture, which prepares the images and provides feature augmentation of the original images.\n","model = models.Sequential() # Calls the (empty) Sequential model from Keras \n","model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(176, 320,3))) #A Convolutional layer is added to the empty sequential model.\n","model.add(layers.MaxPooling2D((2, 2))) #Applying MaxPooling compression technique to images coming from the above convolutional layer.\n","model.add(layers.Conv2D(64, (3, 3), activation='relu')) #Another Convolutional layer is added to the empty sequential model.\n","model.add(layers.MaxPooling2D((2, 2))) #Applying MaxPooling compression technique to images coming from the above convolutional layer.\n","model.add(layers.Conv2D(64, (3, 3), activation='relu')) #Another Convolutional layer is added to the empty sequential model.\n","\n","model.summary() # displays the created model architecture to the screen.\n","\n","#fully connected dnn\n","model.add(layers.Flatten()) #This statement flattens the stack of images received from the convolutional layer and flattens them into a 1-dimensional array.\n","model.add(layers.Dense(64, activation='relu')) # Adds a layer (a hidden layer).\n","model.add(layers.Dense(4)) # Adds the output layer.\n","\n","model.summary()\n","\n","# Optimization \n","model.compile(optimizer='adam',\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","              metrics=['accuracy'])\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9Fi0xCTIkYV7"},"source":["# Model Training"]},{"cell_type":"code","metadata":{"id":"59L9OHXxjHe8"},"source":["# Fit the training data into the model (training) \n","# %debug\n","history = model.fit(X_train, y_train, epochs=7) # training dataset is passed to model for training."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8nu1EvtOkjow"},"source":["# Performance Evaluation"]},{"cell_type":"code","metadata":{"id":"Xi_f34wCjVb8"},"source":["# Assess model using test set ( or validation set too) ( Performance evaluation)\n","scores = model.evaluate(x=X_test, y=y_test) # test is passed to model to evaluate performance of model.\n","print(scores)"],"execution_count":null,"outputs":[]}]}